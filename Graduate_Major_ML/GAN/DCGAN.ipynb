{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f188819",
   "metadata": {},
   "source": [
    "## GAN\n",
    "\n",
    "GAN은 training 데이터 분포를 알아내 같은 분포로부터 새로운 데이터를 생성할 수 있는 모델\n",
    "\n",
    "Generator : training 데이터와 유사한 가짜 이미지를 만들어 낸다.<br>\n",
    "Discriminator : 이미지를 본 후 실제 이미지인지 generator부터 만들어진 이미지인지 출력하는 것이다.\n",
    "\n",
    "\n",
    "## DCGAN\n",
    "\n",
    "DAGAN은 GAN의 확장으로 generator와 discriminator 사이에서 각각 convolution layer와 convolutional-transpose(전치 합성곱)를 사용한다는 점에서 차이가 있다.\n",
    "위 gan은 Unsupervised Representation Learning with Deep Convolution Generative Adversarial Networks 논문에서 처음 발표되었다.\n",
    "\n",
    "Discriminator은 strided convolution layer, BN layer 그리고 leaky ReLU 활성화 함수로 구성되어 있다. input은 이미지이고 output은 input이 실제 데이터 분포에서 가져온 데이터일 확률이다.\n",
    "\n",
    "Generator은 convolutional-transpose layer, BN layer 그리고 ReLU 활성화 함수로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6983cdc",
   "metadata": {},
   "source": [
    "## DCGAN 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713c6a8",
   "metadata": {},
   "source": [
    "https://github.com/YBIGTA/Deep_learning/blob/master/GAN/2017-08-12-DCGAN-korCeleb.markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8337568",
   "metadata": {},
   "source": [
    "### 1. 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94ddd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "#%matplotlib inline \n",
    "import argparse \n",
    "import os \n",
    "import random \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.parallel \n",
    "import torch.backends.cudnn as cudnn \n",
    "import torch.optim as optim \n",
    "import torch.utils.data \n",
    "import torchvision.datasets as dset \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.utils as vutils \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.animation as animation \n",
    "from IPython.display import HTML\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c29ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed :  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22c4673f3b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Random Seed \n",
    "seed = 999\n",
    "print(\"Random seed : \", seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed) # 파이토치 random seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd669cb",
   "metadata": {},
   "source": [
    "### 2. 필요한 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d110c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100 # 노이즈 벡터의 크기\n",
    "nc = 3 # 채널의 수\n",
    "ngf = 64 # generator 필터 조정\n",
    "ndf = 64 # discriminator 필터 조정\n",
    "niter = 200 # 에폭 수\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "imageSize = 64 # 만들어지는 이미지의 크기\n",
    "batchSize = 64 # 미니배치의 크기\n",
    "outf = \"result\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e63351",
   "metadata": {},
   "source": [
    "### 3. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd969096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Scale(64),\n",
    "        transforms.ToTensor(),                     \n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = dsets.CIFAR10(root='./data/', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size= batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3067d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 64, 64]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb2384",
   "metadata": {},
   "source": [
    "CIFAR10은 크기가 32x32 이미지이다. 그런데 dcgan은 일반적으로 64x64 이미지를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e26fc",
   "metadata": {},
   "source": [
    "### 4. weight의 초기값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec9408f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:         # Conv weight init\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:  # BatchNorm weight init\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48617e63",
   "metadata": {},
   "source": [
    "### 5. Generator 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c76e434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            # 입력값은 Z이며 Transposed Convolution을 거칩니다.\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # (ngf * 8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # (ngf * 4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # (ngf * 2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # ngf x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5702f5e",
   "metadata": {},
   "source": [
    "### 6. Discriminator 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44fea4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # (nc) x 64 x 64)\n",
    "            nn.Conv2d(nc, ndf, 4,2,1,bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # ndf x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # (ndf * 2) x 16 x 16\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # (ndf * 4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fa97dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "_netD(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = _netG()\n",
    "netG.apply(weights_init)\n",
    "#print(netG)\n",
    "\n",
    "netD = _netD()\n",
    "netD.apply(weights_init)\n",
    "#print(netD)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "input = torch.FloatTensor(batchSize, 3, imageSize, imageSize)\n",
    "noise = torch.FloatTensor(batchSize, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "\n",
    "label = torch.FloatTensor(batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2727e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e8efbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n"
     ]
    }
   ],
   "source": [
    "epochNum=10\n",
    "loss_D = []\n",
    "loss_G = []\n",
    "score_G1 = []\n",
    "score_G2 = []\n",
    "score_D = []\n",
    "for epoch in range(epochNum):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu, _ = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "\n",
    "        input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        output = netD(inputv)\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        # train with fake\n",
    "        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        netG.zero_grad()\n",
    "        labelv = Variable(label.fill_(real_label))\n",
    "        output = netD(fake)\n",
    "\n",
    "        errG = criterion(output, labelv)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        optimizerG.step()\n",
    "        if ((i+1) % 100 == 0):\n",
    "            print(i, \"step\")\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.data,\n",
    "            '%s/fake_samples_epoch_%s.png' % (outf, str(epoch)+\" \"+str(i+1)),\n",
    "            normalize=True)\n",
    "    vutils.save_image(real_cpu,\n",
    "            '%s/real_samples.png' % outf,\n",
    "            normalize=True)\n",
    "    fake = netG(fixed_noise)\n",
    "    vutils.save_image(fake.data,\n",
    "            '%s/fake_samples_epoch_%s.png' % (outf, epoch),\n",
    "            normalize=True)\n",
    "    result_dict = {\"loss_D\":loss_D,\"loss_G\":loss_G,\"score_D\":score_D,\"score_G1\":score_G1,\"score_G2\":score_G2}\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG.pth' % (outf))\n",
    "    torch.save(netD.state_dict(), '%s/netD.pth' % (outf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf14a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
